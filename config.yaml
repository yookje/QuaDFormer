train_data_path: tsp100_train_concorde.txt
val_data_path: tsp100_test_concorde.txt 
node_size: 100
train_batch_size: 1280  # [tsp50, tsp100] : 1280, [tsp500, tsp1000] : 40
val_batch_size: 1280  # [tsp50,tsp100]: 1280, [tsp500, tsp1000]: 60
test_batch_size: 1280 #128 
G: 1 # multi-start: 20 , greedy : 1 
resume_training : False
resume_checkpoint: logs/lightning_logs/version_108/checkpoints/TSP100-epoch=145-opt_gap=0.6646.ckpt
gpus: [1] #,1] #,1]  
max_epochs: 150 #tsp100=100/tsp1000=400/tsp500 = 340
enc_num_layers: 6 #6 #6 #12
dec_num_layers: 6 
d_model: 256 #128 #256
d_ff: 1024 #512 #1024 #512
h: 8
dropout: 0.1
smoothing: 0.1
seed: 1
lr: 0.5
betas: [0.9, 0.98]
eps: 1e-9
factor: 1.0 
warmup: 400
encoder_pe: 2D #None #, 2D
decoder_pe: circular #None #, 1D, circular 
decoder_lut: memory # shared, unshared, memory
comparison_matrix: memory # encoder_lut, decoder_lut, memory
use_start_token : False
mst_loss_weight : 0.1
feat_dim : 128 #feat_dim=fuzzy_depth*8 +80
grad_clip : False
fuzzy_depth : 6
#self.clip_gradients(opt, gradient_clip_val=0.25, gradient_clip_algorithm='value')60
